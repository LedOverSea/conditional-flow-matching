# 摘要

CNF是生成模型，但是这种方法需要基于模拟的最大化似然训练。本文介绍的一般化的CFM方法，是不需要模拟的CNF训练方法。CFM与扩散模型的近似之处是，他们都有稳定的回归目标，但是CFM的优势在于确定性的流模型能做出高效的推断。进一步提出**最优传输条件流匹配（OT-CFM）变体**，通过小批量最优传输映射构建更简单、训练更稳定、推理更快的流，可近似动态最优传输（OT）。在单细胞动力学推断、无监督图像翻译、薛定谔桥推断等有条件或无条件的生成任务中提升性能。

# 1. 引言

生成式模型的任务是从某个概率分布中近似和采样。**归一化流（NF）**在一个固定分布和数据分布中构建映射，但是这个映射是静态的。之后**连续归一化流（CNF）**的工作是通过神经常微分方程表示这个映射，其不足之处在于难以进行大规模数据的训练。

同时，**扩散模型**在许多生成建模任务上是目前最先进的模型。它通过近似随机微分方程（SDE），将简单的分布转换成需要的数据分布。**流匹配（FM）**与扩散模型近似，通过对常微分方程的回归来训练CNF。FM假设了一个高斯源分布，这个假设在之后更泛化的FM模型中可以松弛。本文的第一个主要贡献是提出**条件流匹配（CFM）**框架，可以适应任何传输映射的FM模型，泛化了已有的FM模型和扩散模型方法

对比其他生成模型，CNF（ODE）和扩散模型（SDE）共同的缺点是，对于微分方程积分需要在网络中经过很多步才能生成高质量样本，所以推断时间会很长。这个缺点推动了利用神经ODE的最优传输（OT）性质的工作，产生一个更笔直的流，从而让积分在更少的网络步骤中完成。本文的第二个主要贡献是**OT-CFM**，这是CFM的变体，能够通过CNF近似动态OT。本文还提出了OT-CFM的变体，用于高效训练CNF以匹配薛定谔桥的概率流

本文的主要贡献有：

- 引入CFM框架的泛化形式，证明其正确性超越其他流匹配方法
- 考虑特殊情形：从OT采样的CFM，可以不需要模拟，只通过边缘分布之间的静态OT映射，解决动态OT和薛定谔桥问题。
- 在以下实验中评估CFM和OT-CFM：单细胞动力学，图像生成，无监督图像翻译，基于能量的模型。OT-CFM训练更高效，减少推理时间，同时对动态OT和薛定谔桥问题有更好的近似解。
- 提供python包，torchcfm

# 2. 背景： OT和神经ODE

在整篇论文中，我们研究的场景涉及d 维欧几里得空间$$\mathbb{R}^{d}$$上的一对数据分布，这两个分布的概率密度函数分别为$$q(x_{0})$$和$$q(x_{1})$$（也可记为$$q_{0}$$和$$q_{1}$$），且密度函数可能是未知的。生成建模的核心任务是拟合一个从$$\mathbb{R}^{d}$$到$$\mathbb{R}^{d}$$的映射f，该映射能将分布$$q_{0}$$转化为分布$$q_{1}$$。具体来说，若随机变量$$x_{0}$$服从密度为$$q_{0}$$的分布，则经过映射后得到的$$f(x_{0})$$需服从密度为$$q_{1}$$的分布。这种场景既包含典型情况（如$$q_{0}$$是易于采样的分布，例如高斯分布），也包含$$q_{0}$$与$$q_{1}$$均为经验数据分布的情况 —— 此时两者可通过有限个样本构成的集合来表示。

## 2.1 ODE和概率流

一个平滑的¹ 时变向量场 $u:[0,1]\times\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}$ 定义了一个常微分方程：
$$
dx=u_{t}(x)\,dt,
$$

用 $\phi_{t}(x)$ 表示具有初始条件 $\phi_{0}(x)=x$ 的 ODE (1) 的解；也就是说，$\phi_{t}(x)$ 是点 $x$ 沿着向量场 $u$ 从时间 $0$ 到时间 $t$ 的传输结果。

给定 $\mathbb{R}^{d}$ 上的一个密度 $p_{0}$，积分映射 $\phi_{t}$ 诱导了一个推前 $p_{t}:=[\phi_{t}]_{\#}(p_{0})$，这是点 $x\sim p_{0}$ 沿着 $u$ 从时间 $0$ 传输到时间 $t$ 的密度。时变密度 $p_{t}$，被视为一个函数 $p:[0,1]\times\mathbb{R}^{d}\rightarrow\mathbb{R}$，由著名的*连续性方程*表征：
$$
\frac{\partial p}{\partial t}=-\nabla\cdot(p_{t}u_{t})
$$
以及初始条件 $p_{0}$。在这些条件下，$u$ 被称为 $p$ 的*概率流 ODE*，而 $p$ 是由 $u$ 生成的*（边缘）概率路径。

**用神经网络近似 ODE。**假设概率路径 $p_{t}(x)$ 和生成它的向量场 $u_{t}(x)$ 是已知的，并且 $p_{t}(x)$ 可以被容易地采样。如果 $v_{\theta}(\cdot,\cdot):[0,1]\times\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}$ 是一个时变向量场，参数化为具有权重 $\theta$ 的神经网络，则 $v_{\theta}$ 可以通过**流匹配（FM）**目标回归到 $u$：
$$
\mathcal{L}_{\text{FM}}(\theta):=\mathbb{E}_{t\sim\mathcal{U}(0,1),x\sim p_{t}(x )}\|v_{\theta}(t,x)-u_{t}(x)\|^{2}.
$$
Lipman et al. (2023)使用这个目标来拟合将高斯密度 $q_{0}$ 映射到目标 $q_{1}$ 的 ODE。但是这个目标难以处理一般的概率分布。

**高斯边缘的情形。**考虑边缘密度是高斯分布的特殊情况：$p_{t}(x)=\mathcal{N}(x \mid \mu_{t},\sigma_{t}^{2})$。虽然生成这些边缘密度的 ODE 不是唯一的，但最简单的一个是满足以下条件的 ODE：
$$
\phi_{t}(x_{0})=\mu_{t}+\sigma_{t}\left(\frac{x_{0}-\mu_{0}}{\sigma_{0}}\right),
$$
根据以下定理，它是唯一的。

**定理 2.1** (Lipman et al. (2023) 的定理 3). *其积分映射满足 (4) 的唯一向量场具有形式*
$$
u_{t}(x)=\frac{\sigma^{\prime}_{t}}{\sigma_{t}}(x-\mu_{t})+\mu^{\prime}_{t},
$$
*其中 $\sigma^{\prime}_{t}$ 和 $\mu^{\prime}_{t}$ 分别表示 $\sigma_{t}$ 和 $\mu_{t}$ 的时间导数，并且具有初始条件 $\mathcal{N}(\mu_{0},\sigma_{0}^{2})$ 的向量场 $u$ 生成高斯概率路径 $p_{t}(x)=\mathcal{N}(x \mid \mu_{t},\sigma_{t}^{2})$。*

## 2.2 静态和动态最优传输

（静态）最优传输问题寻求从一个测度到另一个测度的映射，以最小化位移成本。最受关注的情况是分布 $q_{0}$ 和 $q_{1}$ 在 $\mathbb{R}^{d}$ 上关于欧几里得距离成本 $c(x,y)=\|x-y\|$ 的 2-Wasserstein 距离。相应的优化问题是
$$
W(q_{0},q_{1})^{2}_{2}=\inf_{\pi\in\Pi}\int_{\mathbb{R}^{d}\times\mathbb{R}^{d}} c(x,y)^{2}\,d\pi(x,y),
$$
其中 $\Pi$ 表示所有在 $\mathbb{R}^{d}\times\mathbb{R}^{d}$ 上的联合概率测度的集合，其边缘是 $q_{0}$ 和 $q_{1}$。对于紧支撑分布和基础成本 $c(x,y)=\|x-y\|$，(6) 的解集非空 Villani (2009)，并且 $W_{2}$ 是具有有限二阶矩的 $\mathbb{R}^{d}$ 上概率分布空间上的度量。

2-Wasserstein 距离的动态形式由一个在向量场 $u_{t}$ 上的优化问题定义，这些向量场将一个测度转换为另一个测度：
$$
W(q_{0},q_{1})^{2}_{2}=\inf_{p_{t},u_{t}}\int_{\mathbb{R}^{d}}\int_{0}^{1}p_{t}( x)\|u_{t}(x)\|^{2}\,dt\,dx,
$$
其中 $p_{t}\geq 0$ 并且服从边界条件 $p_{0}=q_{0}$, $p_{1}=q_{1}$，以及连续性方程 (2)。动态和静态最优传输公式之间的等价性首先在 Benamou & Brenier (2000) 中得到证明，假设 $q_{0}$ 和 $q_{1}$ 是具有有界密度的紧支撑分布。我们参考 (Ambrosio & Gigli, 2013, Chapter2) 了解关于最优传输以及两种公式之间关系的最新概述。

Tong et al. (2020); Finlay et al. (2020) 表明，带有 $L^{2}$ 正则化的 CNFs 近似于动态最优传输。然而，对于一般的边缘分布，这些模型需要积分并通过数十到数百次函数评估进行反向传播，导致数值和效率问题。我们的目标是通过以无模拟的方式直接回归到向量场来避免这些问题。

最优传输也与薛定谔桥（SB）问题相关（Leonard, ）。我们在 §3.2.4 中表明，我们提出的算法的一个变体恢复了具有布朗运动参考过程的 SB 问题解的概率流。

注：静态OT和动态OT问题需要对ODE路径进行模拟，其中多次积分以及反向传播计算成本高昂，效率较低。通过以无模拟的方式直接回归到向量场可以避免这些问题。

# 3. 条件流匹配：来自静态耦合的 ODE

## 3.1 生成概率路径混合的向量场

假设边缘概率路径 $p_{t}(x)$ 是概率路径 $p_{t}(x|z)$ 的混合，$z$是条件变量， 
$$
p_{t}(x)=\int p_{t}(x|z)q(z)\,dz,
$$
其中 $q(z)$ 是条件变量上的某个分布。如果概率路径 $p_{t}(x|z)$ 是由向量场 $u_{t}(x|z)$ 从初始条件 $p_{0}(x|z)$ 生成的（见 §2.1），那么向量场
$$
u_{t}(x):=\mathbb{E}_{q(z)}\frac{u_{t}(x|z)p_{t}(x|z)}{p_{t}(x)}
$$
在一些条件下生成概率路径 $p_{t}(x)$：

**定理 3.1**. *边缘向量场 (9) 从初始条件 $p_{0}(x)$ 生成概率路径 (8)。*

这个结果将 (Lipman et al., 2023, Theorem 1) 推广到一般的条件变量，并划定了 $q(z)$ 的一些次要条件。

注：这个定理将目标从ODE路径

**混合的回归目标。**我们感兴趣的情况是，条件概率路径 $p_{t}(x|z)$ 和向量场 $u_{t}(x|z)$ 是已知的并且具有简单的形式，而我们希望恢复由 (9) 定义的、生成概率路径 $p_{t}(x)$ 的向量场 $u_{t}(x)$。通过 (9) 进行精确计算通常是难以处理的，因为分母 $p_{t}(x)$ 是由一个可能难以计算的积分 (8) 定义的。相反，我们开发了一个无偏的随机目标，用于将学习到的向量场回归到 $u_{t}(x)$，这推广了无条件流匹配目标 (3)。

令 $v_{\theta}(\cdot,\cdot):[0,1]\times\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}$ 是一个时变向量场，参数化为具有权重 $\theta$ 的神经网络。定义**条件流匹配（CFM）**目标：
$$
\mathcal{L}_{\text{CFM}}(\theta):=\mathbb{E}_{t,q(z),p_{t}(x|z)} \lVert v_{\theta}(t,x)-u_{t}(x|z)\rVert^{2}.
$$
CFM 目标描述了如何仅给定对条件概率路径 $p_{t}(x|z)$ 和条件向量场 $u_{t}(x|z)$ ，将模型回归到由 (9) 给出的边缘向量场 $u_{t}(x)$。这在以下定理中被形式化。

**定理 3.2**. *如果对于所有 $x\in\mathbb{R}^{d}$ 和 $t\in[0,1]$ 有 $p_{t}(x)>0$，那么，到一个与 $\theta$ 无关的常数为止，$\mathcal{L}_{\text{CFM}}$ 和 $\mathcal{L}_{\text{FM}}$ 相等，因此*
$$
\nabla_{\theta}\mathcal{L}_{\text{FM}}(\theta)=\nabla_{\theta}\mathcal{L}_{\text{CFM}}(\theta).
$$

## 3.2 条件概率路径的来源

在本节中，我们根据 $q(z)$、$p_{t}(\cdot|z)$ 和 $u_{t}(\cdot|z)$ 的选择介绍几种形式的 CFM。所有 CFM 变体及先前工作的相关目标总结在表 1 中。

*   §3.2.1：我们将 Lipman et al. (2023) 的算法（从高斯分布的 FM）解释为 CFM 的一个特例。
*   §3.2.2：我们通过让条件 $z$ 是初始点和终止点对 $(x_{0},x_{1})$ 来放宽高斯源的要求。在 CFM 的基本形式（I-CFM）中，我们将分布 $q(z)$ 取为 $q(x_{0})q(x_{1})$，允许使用具有难以处理密度的任意源分布进行生成建模。
*   §3.2.3：我们考虑由小批量最优传输映射给出的联合分布 $q(z)=q(x_{0},x_{1})$，导致学习到的流是（近似的）最优传输流。
*   §3.2.4：我们考虑由熵正则化的最优传输映射给出的 $q(z)$，并表明具有此 $q(z)$ 的 CFM 目标解决了薛定谔桥问题。

注：本节中主要是对条件变量的分布 $q(z)$做出多种选择 

### 3.2.1 从高斯分布出发的 FM

Lipman et al. (2023) 考虑了给定训练数据集的无条件生成建模问题。将条件 $z$ 与单个数据点 $z:=x_{1}$ 等同，并选择一个平滑常数 $\sigma>0$，可以设置
$$
p_{t}(x|z) =\mathcal{N}(x \mid tx_{1},(t\sigma-t+1)^{2}),
$$

$$
u_{t}(x|z) =\frac{x_{1}-(1-\sigma)x}{1-(1-\sigma)t},
$$

这是一个从标准正态分布 $(p_{0}(x|z)=\mathcal{N}(x;0,I))$ 转移到以 $x_{1}$ 为中心、标准差为 $\sigma$ 的高斯分布 ($p_{1}(x|z)=\mathcal{N}(x;x_{1},\sigma^{2})$) 的概率路径。如果将 $q(z)=q(x_{1})$ 设置为训练数据集上的均匀分布，则 Lipman et al. (2023) 引入的目标等价于针对此条件概率路径的 CFM 目标 (10)。

我们强调，尽管*条件*概率路径 $p_{t}(x|z)$ 是从 $p_{0}(x|z)$ 到 $p_{1}(x|z)$ 的最优传输路径，但*边缘*路径 $p_{t}(x)$ **通常不是**从标准正态 $p_{0}(x)$ 到数据分布 $p_{1}(x)$ 的最优传输路径。

### 3.2.2 CFM 的基本形式：独立耦合

在 CFM 的基本形式（I-CFM）中，我们将 $z$ 与一对随机变量，一个源点 $x_{0}$ 和一个目标点 $x_{1}$，等同起来，并设置 $q(z)=q(x_{0})q(x_{1})$ 为独立耦合。我们让条件分布为 $x_{0}$ 和 $x_{1}$ 之间具有标准差 $\sigma$ 的高斯流，定义为
$$
p_{t}(x|z) =\mathcal{N}(x \mid tx_{1}+(1-t)x_{0},\sigma^{2}),
$$

$$
u_{t}(x|z) =x_{1}-x_{0}.
$$

我们注意到，$u_{t}(x|z)$ 的表述来自于将定理 2.1 应用于具有 $\mu_{t}=tx_{1}+(1-t)x_{0}$ 和 $\sigma_{t}=\sigma$ 的条件概率路径。此外，我们注意到 $p_{t}(x|z)$ 是可以高效采样的，并且 $u_{t}$ 是高效可计算的，因此对 $\mathcal{L}_{\text{CFM}}$ 的梯度下降也是高效的。对于 $z$、$p_{t}(\cdot|z)$ 和 $u_{t}(\cdot|z)$ 的这种选择，我们知道当 $\sigma\to 0$ 时，边缘边界概率分别接近 $q_{0}$ 和 $q_{1}$。这在以下命题中明确说明：

**命题 3.3**. 对应于 $q(z)=q(x_{0})q(x_{1})$ 以及 (14) 和 (15) 中的 $p_{t}(x|z),u_{t}(x|z)$ 的边缘 $p_{t}$ 具有边界条件$p_{1}=q_{1}*\mathcal{N}(x \mid 0,\sigma^{2})$和 $p_{0}=q_{0}*\mathcal{N}(x \mid 0,\sigma^{2})$，其中 $*$ 表示卷积算子。

特别地，当 $\sigma\to 0$ 时，边缘向量场 $u_{t}(x)$ 接近一个将分布 $q(x_{0})$ 传输到 $q(x_{1})$ 的向量场，因此可以被视为 $x_{1}$ 的生成模型。注意，不要求 $q(x_{0})$ 是高斯的。以 $x_{0}$ 为条件允许我们将流匹配推广到具有难以处理密度的任意源分布。在从高斯分布出发的 FM 情况下，虽然每个条件流是从 $\mathcal{N}(x_{0},\sigma^{2})$ 到 $\mathcal{N}(x_{1},\sigma^{2})$ 的动态最优传输流，但边缘向量场 $u_{t}(x)$ 不一定是最优传输流。

**与相关的 Rectified Flow 和 Stochastic Interpolants 方法的联系。**我们注意到 I-CFM 与 Albergo & Vanden-Eijnden (2023); Liu (2022) 提出的算法密切相关。在条件概率路径 $p_{t}$ 是 Dirac 函数（即 $\sigma=0$）的情况下，I-CFM 等价于 (Liu, 2022)。此外，如果我们考虑高斯均值 $\mu_{t}=\cos(\frac{1}{2}\pi t)x_{0}+\sin(\frac{1}{2}\pi t)x_{1}$ 而不是线性插值，那么 I-CFM 将等价于 Albergo & Vanden-Eijnden (2023) 中的方差保持随机插值，该方法也已被进一步推广。

**与从高斯分布出发的 FM 的联系。**存在一组以 $x_{1}$*和* $x_{0}\sim\mathcal{N}(0,1)$ 为条件的条件概率路径，其概率流与从高斯分布出发的流匹配（§3.2.1）的边缘 $p_{t}$ 等价，后者仅以 $x_{1}$ 为条件。这些路径由以下公式定义：
$$
p_{t}(x|z)=\mathcal{N}(x \mid tx_{1}+(1-t)x_{0},(\sigma t)^{2}+2\sigma t(1-t)).
$$
注：Rectified Flow，Stochastic Interpolants ，以及3.2.1的FM都是这节I-CFM的特殊形式

### 3.2.3 最优传输 CFM

在本节中，我们介绍我们的第二个主要贡献。前一节中的公式可以很容易地推广到 $q(z)=q(x_{0},x_{1})$ 中 $x_{0}$ 和 $x_{1}$ 不独立的情况，只要 $q(z)$ 具有边缘 $q(x_{0})$ 和 $q(x_{1})$。因此，我们建议将 $q(z)$ 设置为达到 (6) 中下确界的 2-Wasserstein 最优传输映射 $\pi$，即，
$$
q(z):=\pi(x_{0},x_{1}).
$$
在这种情况下，$z$ 仍然是一个点元组，但 $x_{0},x_{1}$ 不是从它们的边缘分布中独立采样，而是根据最优传输映射 $\pi$ 联合采样。我们称这种方法为*最优传输 CFM*（OT-CFM）。如果使用由 (14) 定义的 $p_{t}(x|z)$ 和 (15) 中的 $u_{t}(x|z)$，那么 OT-CFM 在以下意义上等价于*动态*最优传输。

**命题 3.4**. *命题 3.3 的结果也适用于 (17) 中的 $q(z)$。此外，假设 $q_{0}$、$q_{1}$ 和最优传输计划 $\pi$ 具有正则性，当 $\sigma^{2}\to 0$ 时，边缘路径 $p_{t}$ 和场 $u_{t}$ 最小化 (7)，即 $u_{t}$ 解决了 $q_{0}$ 和 $q_{1}$ 之间的动态最优传输问题。*

我们考虑两种情况：(1) 当数据集足够小并且我们知道静态最优传输计划时（例如单细胞数据）。(2) 当数据太大（或连续）时（例如图像数据），并且静态最优传输计划在计算上难以精确确定。在第一种情况下，我们能够将传输映射扩展到未见过的数据，类似于 Bunne et al. (2023) 中提出的任务。在第二种情况下，我们展示了使用小批量最优传输的近似在生成建模性能和训练时间方面优于随机计划。

**小批量最优传输近似。**对于大型数据集，由于最优传输在样本数量上的三次时间复杂度和二次空间复杂度（Cuturi, 2013; Tong et al., 2020），传输计划 $\pi$ 可能难以计算和存储。因此，我们依赖于类似于 Fatras et al. (2021b) 的小批量最优传输近似。尽管小批量最优传输相对于精确最优传输解会产生误差，但它已成功应用于许多实践，如领域自适应或生成建模（Damodaran et al., 2018; Genevay et al., 2018）。具体来说，对于训练期间看到的每批数据 $\left(\{x_{0}^{(i)}\}_{i=1}^{B},\{x_{1}^{(i)}\}_{i=1}^{B}\right)$，我们从联合分布 $\pi_{\text{batch}}$ 中采样点对，该分布由批次中源点和目标点之间的最优传输计划给出。（最优传输批次大小不必与优化批次大小匹配，但为简单起见，我们保持它们相等。）因此，我们解决了动态最优传输的小批量近似。然而，当最优传输批次大小等于 $(q_{0},q_{1})$ 的支撑集大小时，我们恢复了精确的最优传输，因此，根据命题 3.4，我们学习了精确的动态最优传输。我们凭经验表明，批次大小可以远小于完整数据集大小，并且仍然提供良好的性能，这与先前的研究一致（Fatras et al., 2020, ）。同时，Pooladian et al. (2023) 中出现了一个类似的框架和理论结果。

### 3.2.4 薛定谔桥 CFM

最近，在学习具有一般源分布的扩散模型方面付出了巨大努力，该问题被表述为薛定谔桥问题（De Bortoli et al., 2021; Vargas et al., 2021; Chen et al., 2022）或桥匹配 Peluchetti (2023); Liu et al. (); Ye et al. (2022)。在这里，我们表明 SB-CFM，即 OT-CFM 的一个熵变体，可用于训练一个 ODE 以匹配具有布朗运动参考过程的薛定谔桥的概率流。

令 $p_{\text{ref}}$ 是由 $\sigma$ 缩放的标准维纳过程，其初始时间边缘为 $p_{\text{ref}}(x_{0})=q(x_{0})$。薛定谔桥问题（Schrodinger, 1932）寻求最接近 $p_{\text{ref}}$ 的过程 $\pi$，同时其初始和终止边缘分布由数据分布 $q(x_{0})$ 和 $q(x_{1})$ 指定：
$$
\pi^{*}:=\operatorname*{arg\,min}_{\pi(x_{0})=q(x_{0}),\pi(x_{1})=q(x_{1})} \operatorname{KL}(\pi \| p_{\text{ref}}).
$$
我们定义联合分布
$$
q(z):=\pi_{2\sigma^{2}}(x_{0},x_{1})
$$
其中 $\pi_{2\sigma^{2}}$ 是具有成本 $\|x_{0}-x_{1}\|$ 和熵正则化 $\lambda=2\sigma^{2}$ 的熵正则化最优传输问题（Cuturi, 2013）的解。我们将条件路径分布设置为 $x_{0}$ 和 $x_{1}$ 之间具有扩散尺度 $\sigma$ 的布朗桥，其概率路径和生成向量场为
$$
p_{t}(x \mid z) =\mathcal{N}(x \mid tx_{1}+(1-t)x_{0},t(1-t)\sigma^{2})
$$

$$
u_{t}(x \mid z) =\frac{1-2t}{2t(1-t)}(x-(tx_{1}+(1-t)x_{0}))+(x_{1}-x_{0}),
$$

其中 $u_{t}$ 通过 (5) 计算，作为生成概率路径 $p_{t}(x|z)$ 的向量场。边缘耦合 $\pi_{2\sigma^{2}}$ 和 $u_{t}(x|z)$ 定义了 $u_{t}(x)$，它通过算法 4 中的回归目标来近似。已知薛定谔桥的解是熵正则化最优传输问题的解，这激发了下一个命题。

**命题 3.5**. 由 (19) 和 (21) 定义的边缘向量场 $u_{t}(x)$ 生成与 (18) 中薛定谔桥问题解 $\pi^{*}$ 相同的边缘概率路径。

虽然我们定义 SB-CFM 时熵正则化系数为 $\varepsilon=2\sigma^{2}$，但对于任何 $\varepsilon$ 的选择，该流仍然匹配边缘分布。有趣的是，当 $\varepsilon\to 0$ 时，我们恢复 OT-CFM，当 $\varepsilon\rightarrow\infty$ 时，我们恢复 I-CFM。类似的结果在同时进行的工作 Pooladian et al. (2023) 中得到证明。

# 4. 相关工作

**无模拟连续时间建模。**无模拟训练在随机流模型中很常见，在这些模型中，通过模拟进行反向传播在数值上具有挑战性且方差高（Li et al., 2020）。虽然这些扩散模型最近在许多任务上取得了卓越的生成性能（Sohl-Dickstein et al., 2015; Song and Ermon, 2019, 2020; Ho et al., 2020; Song et al., ; Dhariwal and Nichol, 2021; Watson et al., ），但它们的模拟需要本质上昂贵的 SDE 模拟，并有许多后续工作来改进推理效率（Lu et al., 2022; Salimans and Ho, 2022; Watson et al., ; Song et al., ; Bao et al., 2022）。这些方法通常考虑简单的高斯扩散过程，而不考虑推广源分布。其他工作考虑一般的源分布，但这使得优化和推理更具挑战性，需要多次迭代或其他技巧才能表现良好（Wang et al., 2021; De Bortoli et al., 2021; Vargas et al., 2021）。

先前考虑 CNFs 无模拟训练的工作研究了等价于具有高斯源分布的 CFM 的算法（Rozen et al., 2021; Ben-Hamu et al., 2022; Lipman et al., 2023）或来自 $q_{0}$, $q_{1}$ 的独立样本（Albergo & Vanden-Eijnden, 2023; Albergo et al., 2023; Neklyudov et al., 2023）。最近的工作还研究了来自未配对样本的薛定谔桥（Shi et al., 2022）以及使用动态最优传输对流进行正则化（Liu et al., ）。我们还注意到与本文预印本同时进行的工作 Pooladian et al. (2023)。其他同时进行的工作探索了近似薛定谔桥的各种解决方案（Sonmath et al., 2023; Shi et al., 2023; Liu et al., ）。

**动态最优传输。**有多种方法考虑使用神经网络在连续分布之间进行动态最优传输；然而，这些方法需要受约束的架构（Leygonie et al., 2019; Makkuva et al., 2020; Bunne et al., 2022）或使用正则化的 CNF，这优化起来具有挑战性（Tong et al., 2020; Finlay et al., 2020; Onken et al., 2021; Huguet et al., ）。通过我们的工作，可以在没有这些约束的情况下实现最优传输流。

# 5.实验

在本节中，我们根据最优传输和生成建模标准，评估 I-CFM、OT-CFM 和 SB-CFM 目标，以及先前工作的算法。本节包含低维数据，单细胞插值，高维数据，无监督图像翻译等，这里只举例单细胞实验。

## 5.1 单细胞数据

作为一个具体应用，我们考虑单细胞轨迹插补任务。在此任务中，我们采用时间点的留一验证法：利用时间点$[0,t−1]$和$[t+1,T]$的数据，按照 Schiebinger et al. (2019)、Tong et al. (2020) 和 Huguet et al. (2022a) 的实验设置，尝试插补时间点t的分布。较低的误差意味着我们能很好地模拟单个细胞，这对于基因调控网络推断等下游任务非常有用（Aliee et al., 2021; Yeo et al., 2021）。遵循 Huguet et al. (2022b) 的方法，我们将最近NeurIPS竞赛中的CITE-seq和Multiome数据集重新用于此任务（Burkhardt et al., 2022）。同时我们还包含了来自 Moon et al. (2019) 和 Tong et al. (2020) 的胚胎体数据。在三个数据集上用EMD作为评估指标，OT-CFM平均表现均优于其他方法和基线。

# 6. 结论

我们引入了广义条件流匹配（CFM），这是一个用于训练连续标准化流（CNFs）的无模拟框架，该框架推广了许多现有的流匹配方法。我们提出了 CFM 的一个变体，最优传输 CFM（OT-CFM），它通过 CNFs 近似动态最优传输，并表明它产生了更直的流，训练更稳定，并导致更快的推理。我们在各种条件和非条件生成任务上评估了 CFM 和 OT-CFM，例如推断单细胞动力学、无监督图像翻译和薛定谔桥推断，并表明 OT-CFM 在这些任务上改进了结果。我们发布了一个 Python 包 `torchcfm`，它在共享接口下统一了用于训练基于流的生成模型的新旧算法。
